Perceptrons, a simple form of supervised machine learning, must be trained with a set of known good inputs before they can "learn" by adjusting internal weights assigned to inputs, based on the accuracy of its results. Similarly, we know that reinforcement learning and unsupervised neural networks are able to learn without any known model of the problem; they can be designed to collect information about an environment only by interacting with it. Can symbolic AI be used to design a system that can achieve this "naive learning," or is this a property exclusive to certain soft computing techniques?