I'd like some input on how to keep databases that are running on different servers throughout our organization synchronized. We have a registration system of sorts, and when user "John Doe" registers on server 1, this registration information needs to be instantly available on server 2 and 3. Currently, our network administrators have set up postgresql replication to do this, and it seems to be working fine. When this solution is up and running full scale, we will have 2 databases being replicated to potentially 4 or 5 different servers. Two database because the registration information is saved into two different databases. One database is a CRM, the other is a reservation application. (BTW. This is all on a LAN, vs WAN) What I'm trying to figure out in my head is whether postgresql replication is the best way to do this or if we should be looking at a software solution. I saw one post here where someone was asking about ETL vs. REST API. REST may be a good option I guess. I'm not sure that it completely suits our needs ... I'll have to think about it some more.. But I'm also thinking about Enterprise integration software ... like iway or something like that where you would identify the source database, identify the taraget database... and then define the interval. The tool would then monitor the source database for changes every X minutes. Anytime there is a change, it would update the target databases. But I'm not sure I'm asking myself all the right questions to do a proper evaluation. Here are some I thought of so far:   1. How fresh does the data need to be on the servers? Has to be 'fairly' real-time... I would say within seconds.   2. What's the volume of information? several records could be created in the source database every few seconds.  What else should I be considering? Thanks.