What is the best practice for caching paginated search results whose ordering/properties can be changed? Say, in my application, someone wants to see the last 20 discussion threads (out of 10,000). A request would be sent to the database, via `servlet`, to fetch the first 20 records from the discussion threads table as XML/JSON. If they then want to see the next 20, they go onto the next page of results and this fires off another request to get the next lot (limit and offset = 20, etc.). In order to reduce server load and client-waiting, I would like to cache the previous pages of results. However, I have two questions:   1. The table the results are shown in can be ordered by more than one attribute (i.e., thread-creation-date, thread-author, last-post-date). This means that a statement like 'first 20 results' makes no sense without context (i.e., what are we ordering by). How does the front-end, then, communicate to the back-end what it has already loaded? My first thought was to use IDs for each result but sending these back to the server on subsequent requests (and filtering results based on them) would just as time-consuming as sending everything back blindly. How can I do this?   2. What if an attribute of a previously returned result (i.e., most-recent-post-date) has changed? We then need a way of checking each result to see if it's been modified server-side since it was paged in. How can I do this?