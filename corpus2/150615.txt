This is a repost of a question on cs.SE by Janoma. Full credits and spoils to him or cs.SE. In a standard algorithms course we are taught that **quicksort** is O(n log n) on average and O(nÂ²) in the worst case. At the same time, other sorting algorithms are studied which are O(n log n) in the worst case (like **mergesort** and **heapsort** ), and even linear time in the best case (like **bubblesort** ) but with some additional needs of memory. After a quick glance at some more running times it is natural to say that quicksort **should not** be as efficient as others. Also, consider that students learn in basic programming courses that recursion is not really good in general because it could use too much memory, etc. Therefore (and even though this is not a real argument), this gives the idea that quicksort might not be really good because it is a recursive algorithm. **Why, then, does quicksort outperform other sorting algorithms in practice?** Does it have to do with the structure of _real-world data_? Does it have to do with the way memory works in computers? I know that some memories are way faster than others, but I don't know if that's the real reason for this counter-intuitive performance (when compared to theoretical estimates).