I'm trying to simulate the following equation in _Mathematica_ for $u(x,t)$: $$\frac{1}{\alpha} \frac{\partial u(x,t)}{\partial t} = -u + \int_{-\infty}^\infty {\rm d} y w(x-y) f(u(y,t - |y|/v))$$ where $$w(z)=-\frac{w_o}{2\pi}(1-|z|)e^{-\frac{|z|}{\sigma}}, f[u] = \frac{1}{1+e^{-a(u-\theta)}}$$. So far I've written the following code to do this without the absolute value in `y`, spatial distance and time delays in $u$, which works:               h[z_Real] := Integrate[-(1/(2 Pi))*(1 - y)*Exp[-y]*(1/(1 + Exp[z])), {y, 0, 10}];          solu = NDSolve[{D[z[x, t], t] == -z[x, t] + h[z[x, t]], z[x, 0] == 0.8 Abs[Sin[x]]},                     z[x, t], {t, 0, 5}, {x, -5, 5}];          Plot3D[Evaluate[z[x, t] /. solu], {t, 0, 5}, {x, -5, 5}, PlotRange -> All]      The question I'm asking is whether it's possible to add in the delay. Unfortunately, when I include it and change the initial condition to `z[x,t/;t<=0]=0.8`, I get an error message. Does anyone have a suggestion about how I should proceed? Thanks.