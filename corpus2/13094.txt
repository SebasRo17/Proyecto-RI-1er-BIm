## Background Usually, I give detailed descriptions when I have a question which sometimes lead to that users don't write their answers because they maybe think their answer is too simple. Therefore, I chose to just throw the direct question in the room and collect the ideas of all answers. Although it seems, that we cannot get a simple tokenizer by using functions like `TreeForm`, `MakeBoxes`, `MakeExpression`, ... I want to give some background information now: What really bothers me is, that we have here on Mathematica.SE a highlighter for Mathematica code which is far away from perfect, but which does a reasonable job. If I want to include a snippet of code into a LaTeX document on the other hand, I'm totally stuck with a b/w-pdf export from Mathematica or with the Mathematica **5.2** support of the listings package. Therefore, I hacked a simple parser of the html-output of our google-prettify plugin. This seems to work reasonable and with a little bit adjustment, one could include _styled_ Mathematica-code into a LaTeX document. It should be noted, that I don't intent to export formulas or sophisticated styled code. I want to stick with good old ascii-style code which is used in most packages. Before I used the html-output I was again having a long look at Leonids formatter but at its current state it lacks of the same issues since it relies on `MakeBoxes` as well and there are other issues. Leonid pointed out, that he want to reimplement this completely. On the other hand, we have functions like `SyntaxLength`, `SyntaxQ`, `MakeExpression`, `MakeBoxes` (and their `To` counterparts), all kind of `Forms`, we can keep expressions unevaluated and so on. Therefore, I was asking myself whether we can do the tokenizing much easier with Mathematica that it is possible with the JavaScript from google-prettify. ## Question Is it possible to implement a reliable tokenizer which takes a valid input- string of Mathematica code and returns a list of tokens without implementing the rules of the Mathematica-language itself? Although tokens usually don't contain whitespace characters, for the purpose of testing it would be nice, if **all characters stay even in the tokenized version**. Especially I want               input == StringJoin@@Tokenize[input]      to return `True`. Take for instance this function               Tokenize[str_String /; SyntaxQ[str]] :=        With[{expr = MakeExpression[str, StandardForm]},        Most[Drop[Flatten[MakeBoxes[expr] /. {             RowBox -> List, SuperscriptBox[a_, b_] :> {a, "^", b},              "\[Rule]" :> "->"}], 2]]     ];          Tokenize[     "Plot3D[{x^2+y^2,-x^2-y^2},{x,-2,2},{y,-2,2},RegionFunction->Function[{x,y,z},x^2+y^2<=4]]"     ]     (*      {"Plot3D", "[", "{", "x", "^", "2", "+", "y", "^", "2", ",",       "-", "x", "^", "2", "-", "y", "^", "2", "}", ",", "{", "x",       ",", "-", "2", ",", "2", "}", ",", "{", "y", ",", "-", "2",       ",", "2", "}", ",", "RegionFunction", "->",       "Function", "[", "{", "x", ",", "y", ",", "z", "}", ",", "x",       "^", "2", "+", "y", "^", "2", "<=", "4", "]", "]"}     *)      Although the output looks good here, inside Mathematica we have `\[LessEqual]` instead of `<=` (due to the `StandardForm` I assume). Furthermore, all different kind boxes need to be handled and I'm afraid many more things. Is there any chance to get this working really correctly? **Test examples:** In some of these cases I'm not sure whether my given output is the correct one. E.g. the handling of linebreaks may be system-dependent, `a_` seems to stay together in the box-representation (which would be ok), ...               "a\nb" (* {"a","\n","b"} *)     "a_:>a/2<=3" (* {"a_",":>","a","/","2","<=","3"} *)     "1`3+1.00`3" (* I'm not sure how this should be tokenized but my intention should be clear *)