Many mathematical operation (such as division, multiplication, etc.) are supposed to be computed faster when dealing with power of two numbers (C++, C#?, ...) For instance 15 * 256 = 0x0e right shifted (fast) 8 bits = 0x0e00 = 3840   Whereas 15 * 255 = 0x0e multiplied by (slow) 0xff = 0x0ef1 = 3825 Does this kind of optimization even happen in SQL Server? I don't think there are, I tried measuring a difference of execution time of queries such as those:               SET STATISTICS TIME ON          SELECT         AVG(N / 256)     FROM DBO.V_VIRTUAL_NUMBERS     WHERE N < 1048576               SELECT         AVG(N / 255)     FROM DBO.V_VIRTUAL_NUMBERS     WHERE N < 1000000          SET STATISTICS TIME OFF      which resulted in:                SQL Server Execution Times:        CPU time = 0 ms,  elapsed time = 0 ms.     SQL Server parse and compile time:         CPU time = 0 ms, elapsed time = 0 ms.          (1 row(s) affected)           SQL Server Execution Times:        CPU time = 203 ms,  elapsed time = 207 ms.           SQL Server Execution Times:        CPU time = 0 ms,  elapsed time = 0 ms.     SQL Server parse and compile time:         CPU time = 0 ms, elapsed time = 0 ms.          (1 row(s) affected)           SQL Server Execution Times:        CPU time = 218 ms,  elapsed time = 206 ms.