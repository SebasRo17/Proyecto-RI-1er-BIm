I asked this question over at stackoverflow and it was suggested a tighter form be posted here. Many early career numerical researchers face the prospect of having to create performance critical software from the ground up. Most are ill equipped to do so, and my lab is no different. I currently work extending a sophisticated C application that is typical of a lot of academic code -- it is a nightmare to work with and adding new features takes much longer than it should. I want to learn how to do it better, and I learn by doing. With that in mind, I would like to jump in the deep end and create an application that is parallel (OpenMPI + maybe OpenCL), combines script driven Python UI with C++ for the heavy lifting, and most importantly, makes use of appropriate design patterns to make the code as modular as possible. The primary reason for doing so is to learn the major gotcha's and some general performance techniques that can be documented and shared around the lab. I have read some of the books around OO and pattern's, but I find it challenging to take their abstract nature and apply it to the problem domain in a useful way. I guess the question I am asking is: **if you were given the task to design this kind of software, what would be the focus of your first hour in front of a whiteboard?**