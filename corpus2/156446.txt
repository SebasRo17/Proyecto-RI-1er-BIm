We are starting a project where we will need to write parsers for a bunch of binary file formats, each of them representing very similar data (time-value series from different measurement devices). Since we are starting from scratch, I would like to get it right, and I see two possible approaches:   1. write dedicated, home grown binary parsers for each format separately, or   2. represent binary formats using a grammar, and then use some standard algorithms for lexical analysis/tokenization. Whenever I seek for advice on how to build a parser, I find most guys advocating the latter approach. However, I don't have much experience with formal grammars and languages, and I am afraid that there might be a learning curve before we get results. So, I basically have these questions:   * What is the problem with coding parsers "by hand"?   * Is there a practical "size limit" of a problem when it pays off to invest in learning the "formal approach"?   * Most parsing examples focus on textual files. What is the good way to specify grammar for a binary parser?