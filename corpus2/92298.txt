I am working on a script to get data from excel spreadsheets to a database. The data is from surveys conducted by our office where the data comes in with very little formatting. At the moment, the data is manipulated with a lot of copy and paste, then analysed 'by hand' (ie. someone clicks and drags in excel and does pivots and copy pastes into other software).This leads to messy file structures and missing or incorrect/incomprehensible data. enter the need for a database. I have got a solution working which will accept csv files. It will parse the data and insert it correctly as long as each column header is correct. But my superior is pushing me to accept xml files with an xsd schema so I can validate the data. My argument would be that whether or not I use xml, the user will have to save the original file as another file type and I can validate the data within my script based on column headers anyway. The counter argument is that if they decide to include a new data set (ie, new table layout) my script might break. Either way, if the data type is incorrect, the user will have to go back to the file and edit it before any solution will work. So the answer I'm looking for is whether or not I should bother to set up xml functionality. [note, I am using php to script as I am not familiar with vba and I'm on a student placement so I do not have enough time to learn a new language.] [ASIDE - am I taking the wring approach to this?]