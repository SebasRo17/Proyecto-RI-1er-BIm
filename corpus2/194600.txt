I'm having some issues with my Nexus 7 drawing just 500mA from a USB port able to supply 2.1A (test with my iPad). Details in **this question**. However, there is a comment posted " _The Nexus obviously detects the 'data' pin connected, and assumes it is not permitted to draw more than 500mA (which is the proper USB spec)._ " That got me thinking, how does a device really know how much it's allowed to draw from the USB port? It can't be just via wiring of the D+/D- pins because then you wouldn't be able to communicate over the USB port (eg. Sync'ing or transferring over the USB port). The iPhone and iPad clearly are able to draw higher power from the USB port even during a sync/data operation. So I was thinking, the power it might be officially dictated within the USB comm. protocol itself, perhaps some packet/header. So, **_how does a USB device know whether to draw 500mA, 1A or 2.1A from a computer USB port?_** Does the answer change if the USB port is on a "dumb" wall charger? Or is it a wild west where each device/charger does it's own thing for high current situations?