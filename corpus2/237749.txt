Eric Lippert made a very interesting point in his discussion of why C# uses a `null` rather than a `Maybe<T>` type: > Consistency of the type system is important; can we always know that a non- > nullable reference is never under any circumstances observed to be invalid? > What about in the constructor of an object with a non-nullable field of > reference type? What about in the finalizer of such an object, where the > object is finalized because the code that was supposed to fill in the > reference threw an exception? A type system that lies to you about its > guarantees is dangerous. That was a bit of an eye-opener. The concepts involved interest me, and I've done some playing around with compilers and type systems, but I never thought about that scenario. How do languages that have a Maybe type instead of a null handle edge cases such as initialization and error recovery, in which a supposedly guaranteed non-null reference is not, in fact, in a valid state?