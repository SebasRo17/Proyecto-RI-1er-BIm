Some languages, for exemple java, introduced a low pause GC. Those GC can do most of the work without pausing the whole world. This is obviously a quite hard problem because it require to analyze the memory when thread are modifying it, resulting in data that can be used in the begining of the process and not anymore when it finishes, or data that appears to be garbages but because the reference was moved in memory and never appeared where the GC was looking. So basically, what is the algorithm(s) behind that ? Research papers or really technical article's link would be considered as valid answer, as this topic is really technical.