When having a continuous integration executing the tests at each commit, a common best practice is to have all the tests passing at all times (aka "do not break the build"). I find some problems with that: For example one cannot help an open source project by creating tests corresponding to tickets. I know if I propose a Pull Request to an open source project containing failing test, the build will be marked as failed and the project will not want that merged into its repository because it would "break the build". And **I don't believe it is a bad thing to have failing tests in your repo** , it's like having open issues in your tracker. These are just things waiting to be fixed. The same goes in a company. If you work with TDD, you can't write tests, commit and then write the logic code that fulfills the test. That means if I have written 4-5 tests on my laptop, I can't commit them before going on holidays. Nobody can take back my work. I can't even "share" them with a colleague except by sending them by email for example. It also prevents working with one person writing the tests, the other one writing the model. All that to say, am I misusing/misunderstanding the build process/continuous integration? It seems to me that "passing"/"not passing" is a too narrow indicator. Is there a way to make continuous integration and TDD compatible? Maybe there is a standard solution/practice to distinguish "new tests" (that can fail) and "regression tests" (that should **not** fail because they used to work)?