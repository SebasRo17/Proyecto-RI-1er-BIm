I am trying to maximize the results of a Monte Carlo simulation with respect to some input variables.               ClearAll["Global'*"];     gratInit = 100.; rate7520 = 0.022; rateFree = 0.03;     currentstock = 100.; dividendRate = 0.018;      dividendMult = 1. + dividendRate;     AnnuityPayment = 1/2 (gratInit rate7520) (1/((rate7520 + 1)^yr - 1) + 1);     yr = 2; mu = 0.07; sigma = 0.15; iter = 10000;          returns[years_, mean_, sd_] := RandomVariate[NormalDistribution[mean, sd], years];     rwalks = Table[returns[yr, mu, sigma], {iter}];     d1[K_, T_] := (Log[currentstock/K] + T (-dividendRate + rateFree + sigma^2/2))/(sigma Sqrt[T]);     Call[str_, T_] := 1/E^(dividendRate T) currentstock CDF[NormalDistribution[0, 1], d1[str, T]];               spot[k_] := FoldList[#1 (#2 + 1) &, currentstock, rwalks[[k]]]     Spot = Table[spot[i], {i, iter}];               zRisk[T_, r_] := Quantile[LogNormalDistribution[mu T, sigma Sqrt[T]], r];     StrikeRisk[T_, r_] := currentstock zRisk[T, r];     MCRiskRunIter = Function[{D1, D2, r1, r2, n},       dollarsRisk = {D1, D2};       risk = {r1, r2};      strikePricesRisk = Table[StrikeRisk[i, risk[[i]]], {i, yr}];       priceOfCallsRisk = Table[Call[strikePricesRisk[[i]], i], {i, yr}];       numbOfContractsRisk = Table[dollarsRisk[[i]]/priceOfCallsRisk[[i]], {i, yr}];       MrktRisk = gratInit - Total[dollarsRisk];       For[j = 1, j <= yr, j++,        If[Spot[[n]][[j + 1]] >= strikePricesRisk[[j]],         MrktRisk = -AnnuityPayment + MrktRisk (dividendMult + rwalks[[n]][[j]]) +          numbOfContractsRisk[[j]] Spot[[n]][[j + 1]];,         MrktRisk = MrktRisk*(dividendMult + rwalks[[n]][[j]]) - AnnuityPayment;];        If[MrktRisk <= 0, MrktRisk = 0; Break[]];]; MrktRisk];               MCRiskRun[D1_?NumericQ, D2_?NumericQ, r1_?NumericQ, r2_?NumericQ] :=       (output = Mean[ParallelTable[MCRiskRunIter[D1, D2, r1, r2, n], {n, 1, iter}]];        Print[output]; output)               WP = 6;     PG = 2;     MaxIter = 10;          OptimalResults = NMaximize[{MCRiskRun[D1, D2, r1, r2], {D1 >= 0, D2 >= 0,        D1 + D2 <= gratInit, 0 <= r1 <= 1, 0 <= r2 <= 1}}, {D1, D2, r1, r2}, MaxIterations -> MaxIter, WorkingPrecision -> WP, PrecisionGoal -> PG]      When I run with one processor, everything goes great. When I try to use `ParallelTable` in my function (as above), `NMinimize` evaluates my function for a while, but then stops getting number values for my function. Below is the point in the output file where the transition occurs: > >     68.4242   >     69.5474   >     68.1978   >     69.5474   >     Mean[Join[HoldComplete[{45.6694, 60.7975, 92.762, 44.9912, 75.1937, > 75.7598, etc. >   If I limit the Monte Carlo to 500 or so iterations, it still works fine. But I would like the Monte Carlo to go through 10k iterations or so. Is this a memory issue? Am I doing something wrong? I can provide full code if desired.