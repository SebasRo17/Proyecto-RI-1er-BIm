We have iMac desktops and have just begun to parallelize computations across them see: Wolfram Light Weight Grid and parallel computing. This still does not look like it will give us the performance we would like to see so we've started looking at CUDA. Unfortunately, Apple informs me that CUDA does not work with the iMac's ATI Radeon HD 4670 GPU cards. Further more, one can't replace the ATI cards with NVIDIA cards on an iMac ;-( We do have a MacPro and Apple tells us we can replace it's ATI Radeon card with an NVIDIA Quadro 4000 for Mac.   * _Has anyone had any successful experience running CUDA functions on this NVIDA Quadro 4000 card?_ Apple tells me that the current Mac Pros only support a single graphics card (although the next version of the machine should support multiple ones). This leads to a couple of more questions:   * _Could one setup an array of GPU cards in a separate chassis or maybe in a Linux box that Mathematica could access?_   * _In such a configuration, would one need Mathematica installed on the machine or could it simply see the GPUs as resources on the network?_ Just hoping to understand the range of possibilities. Thanks. * * * P.S. Some more context in response to the first two comments follow. We have to simultaneously process large sets of sequential data (> 10,000 in length) for survival analysis (related to actuarial studies or time to failure studies). We look at a broad set of inner data structures -- think of them as data compression sets or maybe just a subset of possible Permutations[]. We have developed a custom mixture distribution, which models this data pretty well. Using this custom distribution we find we have four types of calculations that appear to take the most time:   * Fitting parameters for the distribution;   * NExpectation[] at each time step (using the distributions described above);   * NSolve[]to find the intersection of pairs of PDFs of the above distributions; and   * NProbability[]  Currently a single study can take 90+ minutes. We have lots of research to do so anything we can do to speed things up would help a lot. Not certain if a CUDA and GPUs can help on the parameter fitting but, as I understand it, GPUs excel at moving large blocks of data around and floating point calculations. _We have lots of data to move in and out of the processors and wouldn't NExpectation[], NSolve[], and NProbability[] all benefit from using CUDA?_