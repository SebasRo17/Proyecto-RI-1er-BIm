I came across this example recently: > If 999 times out of 1,000 an exception will not be thrown then the exception > is only generated once. On the other hand a conditional would have been > called needlessly 999 times, therefore in this case the exception is > superior. In this instance it's C#, but generally speaking is this true? I had previously assumed try/catch statements had their own overhead that would equal the time spent handling a conditional. Granted, just throwing try/catch blocks anyplace a conditional would normally go would be a terrible way to code, but resource-wise does this statement hold up?