There is a task to trace thread execution activity for posthumous analysis with minimum impact on latency/performance. Stack trace might be not enough to understand the reason of crash. Initially I was going to allocate some memory block for every thread and put circular buffer into it. So there wouldn’t be any data races and I can read contents of these buffers in core dump. But this is not really convenient first of all because sometimes core dump is not available (process is running on machine which I don’t have much access). Keeping everything the same but logging trace messages into shared memory would be slightly better because those buffers will not be lost with application crash and other application (which reads shared buffers - let’s call it trace-server) can provide access to traces after main application crash. Is it a good idea? Although I think it will work but do you think it's feasible to go into all these troubles? Have you seen anybody doing this?