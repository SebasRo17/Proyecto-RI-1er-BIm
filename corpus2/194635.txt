Could someone explain the rationale, why in a bunch of most popular languages (see note below) comparison operators (==, !=, <, >, <=, >=) have higher priority than bitwise operators (&, |, ^, ~)? I don't think I've ever encountered a use where this precedence would be natural. It's always stuff like:                 if( (x & MASK) == CORRECT ) ...   // Chosen bits are in correct setting, rest unimportant            if( (x ^ x_prev) == SET )      // only, and exactly SET bit changed            if( (x & REQUIRED) < REQUIRED )   // Not all conditions satisfied      The cases where I'd use:                 flags = ( x == 6 | 2 );     // set bit 0 when x is 6, bit 1 always.      are near to nonexistent. What was the motivation of language designers to decide upon such precedence of operators? * * * For example, all but SQL at the top 12 languages are like that on Programming Language Popularity list at langpop.com: C, Java, C++, PHP, JavaScript, Python, C#, Perl, SQL, Ruby, Shell, Visual Basic.