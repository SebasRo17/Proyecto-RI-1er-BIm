I've been thinking about a side project that envolves web data scraping. Ok, I read the Getting data from a webpage in a stable and efficient way question and the discussion gave me some insights. In the discussion Joachim Sauer stated that you can contact the owners of the sites and architect some way to provide the data that I want. The problem I see is that the websites are generally badly created and apparently seldom have changes in HTML (I don't think they will help me), but the data is relevant. I have suffered a lot using those sites so I would like to aggregate and show them in a better way. So, going with scraping, specifically Scrapy (for python), is a problematic approach? I read that parse.ly uses scraping (Python and Scrapy), but in another context. Given my context, there's a better approach than going with scraping? If going with scraping, how to deal with website structure's changes?