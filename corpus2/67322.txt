I'm wondering if there is any benchmarks which can help to understand real- time characteristics (response time) of non-real-time software. For instance C# application on Windows or MSSQL Server. I know that Windows is not real-time OS, however it does not prevent us to use it in Real-time system if there some additional real-time layer. Let's say we have some real-time system, which reads and store data from some ADC. Data are read from ADC and timestamped on FPGA w/ some real-time Firmware. That part of the system is responsible for taking samples from ADC with some precise interval (let's w/ 10kHz frequency) and for timestamping the data. Afterwards firmware pack samples into data package (let's say 0.1 sec) transfer data via TCP/IP to application on Windows machine. Windows machine should store the data and display it. Yes, application on windows is not real- time as well as TCP/IP connection does not guarantee data delivery in fixed time. For instance   * in some case data transfer might take 0.01sec and 1 sec in another case.    * Windows may interrupt application's threads for a few second.   * application might interrupt itself when garbage collector is working so as a result we may have a few second interrupt in the part of the system which is beyond Controller/Firmware. I.e. response time from non real-time subsystem is varying in some range. However this issue could be solved if there is buffer big enough on controller, so it can accumulate data waiting for response from non real time subsystem. In order to be sure that buffer on real-time subsystem is big enough to support non-real-time subsystem we need to understand response time probability distribution. Something like:   * response time <1sec in 80% cases   * 1sec    * 2sec    * 5sec    * 10sec  That is basically the question. Any benchmarks for Windows, C# or MS SQL? Any methodic? TPC does nice benchmarks for SQL Servers performance however they total performance, and do not consider response time AFAIK.