In the course of a programming problem I stumbled upon the following sub- problem. Given an arbitrary, but fixed, number of Boolean variables, I would like to be able to pick a subset of the variables and combine them in such a way that I get a numbering of the unique cases that the subset possesses. To give an example, let $A, B, C$ be three Boolean variables. The truth table has the form $$\begin{array} {|c|} \hline A & B & C \\\ \hline 1 & 1 & 1 \\\ \hline 0 & 1 & 1 \\\ \hline 1 & 0 & 1 \\\ \hline 0 & 0 & 1 \\\ \hline 1 & 1 & 0 \\\ \hline 0 & 1 & 0 \\\ \hline 1 & 0 & 0 \\\ \hline 0 & 0 & 0 \\\ \hline \end{array}$$ Take the subset of variables to be $\\{A,C\\}$. It would be great to get a numbering of the different cases implied by $A$ and $C$ in the following way, $$\begin{array} {|c|} \hline A & C & Numbering \\\ \hline 1 & 1 & 1 \\\ \hline 0 & 1 & 2 \\\ \hline 1 & 1 & 1 \\\ \hline 0 & 1 & 2 \\\ \hline 1 & 0 & 3 \\\ \hline 0 & 0 & 4 \\\ \hline 1 & 0 & 3 \\\ \hline 0 & 0 & 4 \\\ \hline \end{array}$$ What would be the most efficient way to getting the vector containing the numbering of the different cases? I thought of generating the truth table, combining the truth values of the chosen variables into a unique symbol, i.e. the string consisting of the respective truth values, 1 1 -> "11", eliminating the redundant symbols in that vector and mapping back the indices of the symbols in that smaller vector to the symbols in the vector containing the redundant symbols. However, that seems to be horribly inefficient. Is there a Mathematica- specific way to optimize this, possibly one which would allow it to be extended to multi-valued variables? **Edit** : It seems to be inefficient because the choice of the subset and the total number of variables uniquely determine the numbering vector.