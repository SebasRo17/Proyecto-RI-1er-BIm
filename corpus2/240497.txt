I am working on a system to detect an "embedded" 12 bit number within a series of frames that are recorded inside an mp4 file. The point of it is to automatically identify the "take", and also trim the start of the file to a common offset for synchronization with other files. this is typically done manually, but the nature of the project demands it needs to happen as much as possible automatically. It's not possible to set the timecode in the camera. The number is generated by a smartphone app, which I have coded a prototype for, but as I am new to image processing, I need some help figuring out how to do the other side of the equation. this algorithm, for what it's worth doesn't need to be real time, and will probably happen in a pc based command line utility, not that it's that relevant to the algorithm itself. My original idea was to use a QR Code, but I found the resolution and artifacts from the mp4 stream were too much to cope with it in all lighting situations and frame rates. So I came up with the idea of sending the number serially, by encoding it in a distinctive series of squares, using RGB colours, which seems to be efficiently handled without too many "artifacts" at speed by the mp4 encoder. (This I am determining by manually looking at the video frame by frame, not programmatically) Which whilst it is a slow way to send the number, it can be accurately synced to a known time datum, and the precise frame extrapolated from there (I take precisely 1 seconds to send the 12 bits), which most frame rates can keep up with.) To check the images are "human readable" I have extracted frames, and I am confident that it is now a fairly trivial task to analyse each frame to decode each bit of the number. so breaking it into manageable chunks, here is what I need to be able to do:   * Detect a "solid" red square   * Detect 4 squares within each other that are red,green,blue, and white    * Detect 4 squares within each other that are red,green,blue, and black  The last 2 would effectively be the same algorithm, as i would just change parameters. there's an variation on that theme, but it's not that relevant to the algorithm, i just means swapping the blue and green around, to detect the frame rate. **Solid red square** ![red square solid](http://i.stack.imgur.com/1wZKM.jpg) **Red square, a green square, and a blue square, white square:** ![enter image description here](http://i.stack.imgur.com/vhbKm.jpg) **Red square, a green square, and a blue square, black square:** ![enter image description here](http://i.stack.imgur.com/wyei2.jpg) The algorithm would need to be able to work independent of the previous frame, but would need to return the bounding rect of the red square in each case, for validation purposes. I could in theory attempt this myself, but what i am not sure how to handle is the fact the squares might not be exactly "level". aside from rotating the image multiple times by a few degrees, I can't think how to detect it accurately.