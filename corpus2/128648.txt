It seems that as experience with the specific set of tools you have to work with grows, the incentive to try out new things weakens. When I was new at this programming job, trying out new things, researching online, made me _more_ productive, because I often found a way (or library) that made the task easier that the code framework already in place. So using something new -- to me as well as in the context of the given codebase -- made me more productive. Now I noticed, that there are more and more instances where, for a given problem, I _know_ that there probably _is_ a better solution "out there", and finding it would -- presumably -- improve the code. However, given my now intimate knowledge of the code base, it is by far easier to use the suboptimal tools we have, and get a solution (including tests) running than find someting new and "better" and "improve" the codebase. So there is this tension: "do it properly" vs. "get the job _decently_ done". Is this something that happens to a lot of developers? Is this a known specific problem? (Is it a real problem after all?) Does it actually have to do with increasing levels of experience? Oh, and note: I still like my job and like to keep it. It's just that it seems the -- always interesting! -- research part get's smaller as I learn the code base and problem sets we face with our app.