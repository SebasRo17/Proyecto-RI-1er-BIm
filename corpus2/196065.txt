I am working with A* algorithm, in which I have a 2D grid and given two points, find the shortest distance between them, while not running into any obstruction. Now, for each cell, I find the distance from the source, and calculate the distance from destination. Add the two quantities, and the one that has the minimum value, that cell is considered next. Now, How do I calculate the running time of such an algorithm, since I'll never know how many times this process will be repeated. i.e how many cells will I have to work, with, before I reach my destination. Kindly help. I am looking for the upper bound of running time. In terms of the length of side of grid, i.e. N. Thanks.