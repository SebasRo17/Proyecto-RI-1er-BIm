* When Google, Bing or Yahoo are crawling content from Web sites, what makes it legal? Is there a public registry of only allowed crawlers?    * When researchers are crawling Deep Web, what makes their efforts legal?   * When tester automate their tests with Selenium or JMeter and hit same site multiple times, what makes their effort illegal? In each of those cases, an automate is consuming Internet bandwidth of the Web site, and copying their content. But some are considered legal, and other are not.