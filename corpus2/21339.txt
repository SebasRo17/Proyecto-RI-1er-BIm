I have been using the http:BL to block bad IP's from accessing my site. If a malicious IP (comment spammer) trys to hit the site I just `exit` the web script which implicitly returns a `200 OK` response. Other responses I could return: 404 - Not found? If I return a 404 maybe the robots will think "this is a waste of time, lets move on to attack another site" which would reduce the load on the site (I currently get about 2 spam-hits per second). However   * I'm reluctant to return 404's on urls that, under normal circumstances, _can_ be found.    * I'm not sure if spam robots can 'waste time'. i.e Why would a bot writer be bothered to code for 404's when they just blitz the web anyway? 401 Unauthorized? Blocking a bad IP is not quite the same as "resource requires user authentication 1) which has not yet been provided or 2) which has been provided but failed authorization tests" * * * In general I feel that 'responding to the bad-bots according to proper http protocol' gives the bad guys the upper hand. In the sense that I play by the rules while they do not (a bit like Britain in the EU - ha, ha). On some days I feel like I should do something clever to divert these bot's away. On other days I just think that I should not take it personally and just ignore them. Accepting it as par for the course of running a web site. I dunno - what are your thoughts? How do you respond when you know its a bad IP?