**Objects Never? Well, Hardly Ever** In the VIEWPOINT section of Communications of The ACM, I found an interesting article entitled "Objects Never? Well, Hardly Ever". Itâ€™s a radically different perspective than objects-first or objects-late. He suggests "objects-never" or maybe "objects-graduate school". The author talked about OOP and made a question about how OOP is used in real world programming environments. He thinks that OOP is not the dominant programming model. For example, he claims, 70% of programmings are done for Embedded Systems where OOP is not really suited. When some professors in universities wants to talk about the benefits of OOP, they talk about code-reuse. As another example, again, he claims, this is not the real case in real world. code-reuse is harder than what's claimed in universities. I claim that the use of OOP is not as prevalent as most people believe, that it is not as successful as its proponents claim, and, therefore, that its central place in the CS curriculum is not justified. It's interesting for me to know how people in stack-overflow think about this? Is OOP the dominant programming model from programmers' point of view? PS: I asked this on StackOverflow, but someone suggests it should be asked here. hope to find a good result :-) PS2: If I should choose/learn/use just one approach, is it OOP or not? why?