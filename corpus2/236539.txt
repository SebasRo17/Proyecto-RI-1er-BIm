I want to implement a parallel clustering algorithm "out-of-core" in CUDA. My CPU has **12GB** of RAM and GPU has **4GB** of it. What I want is that the entire dataset should be on the disk, and I can pick blocks of data from it, put the blocks on CPU memory, pass them to the GPU, process it there and store the result back on disk. The step complexity of the original (in-memory) algorithm is **O(logN)** , N-> no. of data points. For the external memory algorithm, suppose M points can fit in the memory at once, then according to me, the running should be               (N/M)*(logM)      (N/M) -> equals the number of such sets of points that will have to be put in memory and during each pass, logM time to process it. How does this running time relate to the I/O time between disk and memory, i.e., have I already considered the I/O time by using (N/M) or am I leaving something out? Is this analysis correct, or do I need to know more about Input/Output to implement an algorithm using external memory?