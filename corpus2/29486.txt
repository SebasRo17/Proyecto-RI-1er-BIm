1 + f[1] // N       gives                1. + f[1.]        I don't want the argument of `f` evaluated by N; I want to get               1. + f[1]      instead. In general, there is a large algebraic expression containing some subexpressions of type `f[__]`. `N` should not be applied inside `f`. `N` should be applied only outside. Mapping `N` at a certain level only is **not** OK, since the tree structure of expression is not know in advance. One possible trick is               1 + f[1] /. x_f :> 1. x + 0.       It would be good to know other options.