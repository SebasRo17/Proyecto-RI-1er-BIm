_background story:_ So, we want to have a distributed cache available to all applications. (Non- concurrent writes, concurrent reads). In ideal case, the cache must be persistent and kept in RAM _(that's what Redis does..)_ , and the older data must be available at request, and the whole thing must not be implemented as an application-level partitioning/sharding (this is considered bad because such code would be scattered around the whole project). Due to short timeframe for the project and other reasons, a number of strange solutions is getting reviewed/evaluated here; one of them is redis_fdw, a Foreign Data Wrapper or PostgreSQL. (We understand that, while SQL/MED specifications covers a vast number of situations, it doesn't fits our 'fast cache' scenario) * * * There are Redis fork/clones working with persistent storage without loading whole dataset into RAM, and they are protocol compatible. This allows to implement either 'fast' or 'large' store (we have ~20GB workset and a 10x to 100x larger history read-only set).. So, a decision on retrieving historical data should be made; how should it be decided to implement data source selection in such situation: in application layer, or in data layer? (By data layer, here I mean a caching/HA solution simular to twenproxy) Of course, if there are better solutions than Redis/RDMBS or Redis/edis (Erlang fork of Redis with large on-disk dataset support), let me know too.