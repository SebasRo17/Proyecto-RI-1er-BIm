Hi I have a programming problem that I would like to solve using some artificial intelligence technique. I really dont know where to start. I would like some guidance as to what methodology to pursue. Lets say I have 10,000 images of random people, and I need to detect elderly people in images. I might have algorithms like wrinkle detector, glasses detector, walking cane detector, missing teeth detector, skateboard detector, Playstation detector, etc. Each algorithm does a scan independently and outputs a number from 0 to 10 on the likelihood it thinks the image contains that item. Lets assume that works. There might be 100 different algorithms. My set of 10,000 images would be divided by a human into two groups, those that contain an elderly person, and those that do not. Now I need to develop a system that takes the series of values from the algorithm modules, when given an image to analyze, and calculates a single value that represents the likelihood that an image has elderly people in it or not. During training I would like it to be able to automatically build rules by analyzing all the algorithms' outputs. For example:   * If wrinkle detector, glasses detector, walking cane detector and missing teeth detector all output a high number, then output a high number.   * If wrinkle, glasses, cane and teeth detectors are high, but playstation and skateboard detectors are also high, then output is neither low nor high.   * hands detector and clothes detector should be essentially ignored as old and young people both have those (hopefully) What type of technology should I be implementing for the automated rule building system? Is this better solved by a neural network system? A fuzzy logic system? Something else? Thanks for any advice.