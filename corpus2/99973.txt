Since the beginning of the Javascript race -- which I would situate around Google Chrome launch in 2008 -- the improvement in the Javascript engine performances have been impressive. The web is crowded with comparisons such as "Firefox V3.42.7 vs. Safari 3.0-prealpha2", and the winner of those comparisons changes every few months and differs on each benchmark. But the big picture, independently of who got their new version out last, is that the average speed of current up-to-date browsers has improved a lot over the last years. Yet this long-term improvement is difficult to quantify:   * people usually compare the last version of each browser, and not different versions of one browser   * announced performance improvements do not generally pile up: when someone announce V3 twice as fast as V2, and later V4 twice as fast as V3, this does not mean that V3 is fourth times as fast as V1, because they usually mean "in a favorable case", and the favorable case in the V3-4 transition are not necessarily the same as in the V2-3 transition   * benchmarks themselves evolve over time; what is referred as "the Sunspider test" today is not the same as in 2008, so we cannot compare raw scores over time. Does anyone know of a valuable measurement of javascript engines performance improvement over the last few years?