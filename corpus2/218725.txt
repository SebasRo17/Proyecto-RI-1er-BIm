I'm very excited about Docker, if you're a developer in a big project you've suffered too much at the _machine_ hands of environments and multi-platforms. One of the key selling points of Docker is that by snapshotting/committing image state you avoid the risk of building an environment with a different version, possibly incompatible, of a given dependency. I get that, great! Doing the tutorials on dockerfile, isn't this exactly the same concept as running `npm`, `chef` or `bower`. Of course unix libraries would be more stable than most of the ones found on these library stores I just mentioned but isn't this the same workflow that docker is fighting? Isn't the goal to tailor a container to your needs and then commit it's state to then multiply at will? Am I missing something trivial, or this is the case? Does docker still gives you a chance for building up images from script files and by that it steps on it's toes?