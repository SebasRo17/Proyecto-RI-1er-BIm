I am an undergraduate student and I have to create a Semantic Network based on Wikipedia. This Semantic Network would be similar to Wordnet(except for it is based on Wikipedia and is concerned with "streams of text/topics" rather than simple words etc.) and I am thinking of using the Wikipedia XML dumps for the purpose. I guess I need to learn parsing an XML and " _some other things_ " related to NLP and probably Machine Learning, but I am no way sure about anything involved herein after the XML parsing.   * Is the starting step: XML dump parsing into text a good idea/step? Any alternatives?   * What would be the steps involved after parsing XML into text to create a functional Semantic Network?   * What are the things/concepts I should learn in order to do them?   * I am not directly asking for book recommendations, but if you have read a book/article that teaches any thing related/helpful, please mention them. This may include a refernce to already existing implementations regarding the subject. Please correct me if I was wrong somewhere. Thanks! EDIT: The final product should be like a complete Semantic Network (like Conceptnet or Cyc etc.), So I can't use things like Semantic Mediawiki. (On a second thought, it seems like I should have asked this question on linguistics and not here... )