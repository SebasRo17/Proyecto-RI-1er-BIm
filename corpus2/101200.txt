My task lays in the area of text mining / labelling, more particular extraction of bibliographic citations (references) from the plain text, as shown here: ![enter image description here](http://i.stack.imgur.com/CjLn6.png) Basically, for the input text the algorithm should recognize:   * The beginning and end of citation   * Journal name, title, author, issue, volume, pages This task was already approached in e.g. Citation Parsing Using Maximum Entropy and Repairs (Ng Yong Kiat, 2005), which demonstrated that CRF models deal better then MEMM or pattern-based approaches. Currently there are two projects, that do the job:   * ParsCit, a Perl program build on the top of CRF++ project   * Grobid – Java module, also based on CRF++ While the results of mentioned approaches are already known (and are very good), I was given a task to do the same but using the context-free grammars. Indeed, the information looks to be very structured but I am not sure if this approach can outperform CRF on sensitivity, at least I hope it can beat it on accuracy. My idea is the following:   * Define the fixed grammar rules for already known types:   `YEAR → (19|20)\d\d | \d\d\d\d`   `PAGE → \d{1,3}\-\d{1,3} | e\d{1,3}`   `ISSUE → \d{1,3}`   * It is possible to infer from training set the probabilities of rule alternatives e.g.:   `PAGE → \d{1,3}\-\d{1,3} with P=0.8 | e\d{1,3} with P=0.2`   * From the pre-annotated training set generate the high-level rules (all chars between non-terminals are terminals):   `CITATION → AUTHORS, JOURNALTITLE, ISSUE, PAGES, YEAR | AUTHORS, BOOKTITLE, VOLUME, CHAPTER, CHAPTERTITLE, EDITORS, PUBLISHER, PUBPLACE | ...`   `CITATIONS → CITATION | CITATIONS; CITATION | CITATIONS; and CITATION` The problematic places are:   * `AUTHORS`: There is no fixed rule for them, but one can write a function, that can score that the given text looks like an author. Also the list of possible (English) surnames is not so huge, but if I create the thousands of rules it will slow down the grammar parser. Let's say for authors we have some scoring function, that for given input returns a number [0 .. 1] reflecting how the input really looks like an author. The grammar parser should feed all possible variants for `AUTHORS` and stop on one with a best score.   * `JOURNALTITLE`: The same story. There is obviously no general rule to define it. There is a list of all journals, but then comes also the subproblem of abbreviation: _Ann. NY Acad. Sci. = Ann N.Y. Academy Sci = Annals of the New York Academy of Science_. Again, we can define a scoring function for that; in worst case the function can measure the distance between input sting and all known journal titles using Damerau–Levenshtein algorithm.   * The text like "Vol", "Chapter", "edited by" can be very useful as terminators prefixing the corresponding values (and thus reducing the ambiguity of the grammar), but can they be identified and learned automatically?   * The same for terminators before and after citation, which can be very useful (perhaps will speedup the parsing):   `SUPERCITATION → ( CITATIONS ) | ( see, e.g., CITATION ) | see, for example, CITATION | described in, e.g., CITATION | is disclosed by CITATION`   Does it make sense to "hardcode" them or try to learn them?   * The "noise" text between citations: how to deal with it? The goal of the lexical analysis is perhaps not to find the most probable parse tree, but also to maximise AUTHORS and JOURNALTITLE functions. Can somebody advise me:   * If SCFG is the right way to approach the problem? If yes, how is it possible to adapt this approach to create a parse tree based on probabilities and also on scoring functions?   * Are there any other relative works / articles?   * Are there any libraries that can help in chunking the text (written in a way that can be applied also for e.g. Chinese text)? I have found some monsters like UIMA, Mallet, MinorThird... I wonder about your personal experience when using them for the task like above. Thank in advance for any reply.