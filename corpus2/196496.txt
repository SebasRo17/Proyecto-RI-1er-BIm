I have a large module which have to process more than 10k request/ response per second. Every request has a json and need to process it and verify it on the database and generate the response on the basis of the db query. Here is an example                Function 1           function  ('/get' , fucntion (req1 , res1 , next ){            //to process the req data        processData(req1 , res1 );           });                Function 2               processData(req1 , res1 ){                var J = JSON.parse (req1.body)          //it has to read db three times           //process the json build the response and return                      condtionCheck(J , res1){                              var a = someVlaue(){                         //select a value from a collection set of nosql which have                          //more than 1000 document and                          //i have to itrate a for loop to check the condition .....etc                          //...........                                }                         ........                                dataRead(var a , res1){                  // is it possible to send response for the req1 object here                              res1.send({value b: abcd123})                         }                        }                }               Function 3 ..... and so on       The major problem is all the code i have written inside the process data is synchronous. Bacaue each code depends upon the previous call back and there are so many condition check are used in several times. So It is good to put such a large processing in synchronous way inside node ? If i write the code using async some times all scenario got in a deadlock condition How to avoid such behavior? Does async or function like step have affect on performance ? On such a series of function how can we reduce latency ?