We are developing a Qt-based application to navigate through and paint on a volume treated as a 3D pixel graphic. The layout of the app consists of three orthogonal slice views on which the user may paint stuff like dots, circles etc. and also erase already painted pixels. Think of a 3D Gimp or MS Paint. _How would you design the the architecture for the different interaction modes (i.e. paint tools)?_ My idea is:   * use the MVC pattern   * have a separate controler for every interaction mode   * install an event filter on all three slice views to collect all incoming user interaction events (mouse, keyboard)   * redirect the events to the currently active interaction controler I would appreciate critical comments on that idea.