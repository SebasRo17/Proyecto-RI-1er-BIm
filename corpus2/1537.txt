I'm new to Mathematica, so I thought I'd try to exercise some solution curves. Consider a simple first order ODE: $y'(x)=\cos(x)$. We know the solution will be of the form $y = \sin(x)+c$ I tried to use a `Table` function to generate a list of solutions that I'd then use with the `ContourPlot` function as follows:               solns = Table[y = Sin[x] + i, {i, -5, 5}]      Then use `ContourPlot`:               ContourPlot[y == solns, {x, -5, 5}, {y, -5, 5}, FrameLabel -> Automatic]      But examine the label of the ordinate! It appears as:               sin(x)+5      The trouble lies in the definition of `solns`; when `y=Sin[x]+i` is used, for some reason the output is still the correct list that we expect:               {-5 + Sin[x], -4 + Sin[x], -3 + Sin[x], -2 + Sin[x], -1 + Sin[x],       Sin[x], 1 + Sin[x], 2 + Sin[x], 3 + Sin[x], 4 + Sin[x], 5 + Sin[x]}      However `y` is set equal to the last value in this list as an unintended consequence. My question here is several fold:   1. Is `y` being set to each element in the output list in turn, and only the last value is being used?   2. Why didn't the output after I had evaluated this function show this sort of 'side effect'? I'd have expected it to be on the 'output' line associated with the Table function.