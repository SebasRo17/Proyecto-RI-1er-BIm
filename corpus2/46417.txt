I have the following $\;3\times3$ matrix: $\left( \begin{array}{ccc} 0.04 -0.4 b & 0 & 0.04 -0.4 b \\\ 0 & -0.08-1.2 b & -0.06-0.9 b \\\ 1.04 -0.4 b & 2.08 -0.8 b & 0 \end{array} \right)$ I want to find the $b$ values that make any of the eigenvalues of this matrix is $0$. When I calculate the eigenvalues I get the following: > >     {Root[- 0.00832 - 0.0384 b + 1.264 b^2 - 0.48 b^3 + (0.08 + 2.24 b - 0.4 > b^2) #1 >           + (0.04 + 1.6 b) 2 + 1. #1^3&, 1], >      Root[- 0.00832 - 0.0384 b + 1.264 b^2 - 0.48 b^3 + (0.08 + 2.24 b - 0.4 > b^2) #1 >           + (0.04 + 1.6 b) #1^2 + 1. #1^3&, 2], >      Root[- 0.00832 - 0.0384 b + 1.264 b^2 - 0.48 b^3 + (0.08 + 2.24 b - 0.4 > b^2) #1 >           + (0.04 + 1.6 b) #1^2+1. #1^3&, 3]} >   Now I want to get the $b$ value that makes the real part of any of the eigenvalues $0$ with the following command:               Map[ NSolve[ Re[#] == 0 && b âˆˆ Reals, b] &, eigs]      _Mathematica_ finds that the real part of the first eigenvalue will never be $0$, hence produces an empty set. However, for the roots $2$ and $3$, it does not evaluate the command. Also, first root is 0 when $b=0.1$ as I can see it in the plot below (red dots). ![Eigenvalues with respect to $b$](http://i.stack.imgur.com/mR71F.png) Is there any way to find $b$ more effectively?