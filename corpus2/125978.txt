I am writing a small personal archiving tool. I frequently work with a lot of client databases for short periods, what my tool will do is in overnight batch jobs it will detach the database and zip up the database files and any extra files that where sitting in the folder that the database resided in and move it to a network storage drive. My question is quite frequently there will be zip files sitting inside the folder (the most common one would be the client's original backup before I did the processing on it). Would it be better to unzip the file to a unique sub- folder name, delete the zip, then compress the whole parent folder, or are compression algroithoms good enough that I could leave the file zipped (it was likely done with a 7zip Fastest setting) and my archiving (which will be a 7zip Ultra setting) will just compress (mostly) the difference between the two compression levels? If I can get another 1% off of a 20GB database file it may be worth it to do the decompression.