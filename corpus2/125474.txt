I've been working under the share-nothing principle of concurrent programming. Essentially, all my worker threads have immutable read-only copies of the same state which is never shared between them ( _even by reference_ ). Generally speaking, this has worked really well. Now, someone has introduced a no-lock singleton cache ( _e.g. a static dictionary_ ) that all the threads are accessing concurrently. Since the dictionary is never altered after startup there are no locks. There haven't been any Thread-Safety issues, but now there is a performance degradation. The question is... since there are no locks why does the introduction of this singleton create a performance hit? What exactly is going on under the covers that could explain this? To confirm, accessing this new singleton is the only change and I can reliably recreate this simply by commenting out the call to the cache.