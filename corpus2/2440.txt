## First example Suppose you want to calculate the 6th power of some matrix $A$. The brute force attempt of doing this is considering $$(((AA)A)A)A)A$$ which requires a total of 5 matrix multiplications. However, this can be improved on by smart grouping of the matrices, for example $$((AA)A)((AA)A)$$ requires only 3 multiplications, since when the value of say $AA$ is known from the left parenthesis, it does not have to be recomputed on the right hand side. Using this type of caching can save a lot of computational power (logarithmic scaling?). ## Second example A lot more computation is necessary if we're not multiplying matrices but differential forms, since each multiplication requires the calculation of a whole lot of permutations in addition to the multiplication of the components. For example, the Liouville form in classical mechanics is $$\omega^n\propto\underbrace{\omega\wedge\omega\wedge\cdots\wedge\omega}_{n~\text{factors}}$$ where each $\omega$ is a 2-form. ## The question Since this already smells like a good application of Mathematica's "`x := x =`" trickery, I would like to solve this problem in general: **How do I divide the operations up in a smart way such that I have to do as little computational steps as possible, and how do I implement this in Mathematica?** Note that matrices were only an example application (otherwise the answer would be `MatrixPower` of course), I sumbled upon that problem a couple of times in the past in very different situations, and had to resort to possibly very ineffective implementations. ## Mathematical statement Take an associative algebra $\mathcal A$. How can $a^n$ with $a\in\mathcal A,~n\in\mathbb N$ be calculated using as little computations as possible?