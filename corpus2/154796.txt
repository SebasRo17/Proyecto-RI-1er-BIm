I know this sounds a lot like other questions which have already being asked, but it is actually slightly different. It seems to be generally considered that programmers are not good at performing the role of testing an application. For example: Joel on Software - Top Five (Wrong) Reasons You Don't Have Testers (emphasis mine) > Don't even think of trying to tell college CS graduates that they can come > work for you, but "everyone has to do a stint in QA for a while before > moving on to code". I've seen a lot of this. **Programmers do not make good > testers** , and you'll lose a good programmer, who is a lot harder to > replace. And in this question, one of the most popular answers says (again, my emphasis): > Developers can be testers, but they shouldn't be testers. **Developers tend > to unintentionally/unconciously avoid to use the application in a way that > might break it.** That's because they wrote it and mostly test it in the way > it should be used. So the question is _are programmers bad at testing?_ What evidence or arguments are there to support this conclusion? Are programmers only bad at testing their own code? Is there any evidence to suggest that programmers are actually _good_ at testing? What do I mean by "testing?" I do _not_ mean unit testing or anything that is considered part of the methodology used by the software team to write software. I mean some kind of quality assurance method that is used after the code has been built and deployed to whatever that software team would call the "test environment."