I'm currently designing a somewhat large program that will involve the simulation of math/physics models and collection of data (I have not implemented any code yet). One of the main problems I'm facing is how to pass data around easily without having to have multiple copies of data (that may potentially be outdated and redundant). Initially I was thinking of having the model objects each implement a function that returns a data structure containing copies of their data, then collecting all those data structures together and passing that around. This would involve a lot of copying however, and the data wouldn't be mapped to the actual object anymore. (The data structure idea I had would involve using a trie so that the data is nice and hierarchical and lookups can be done easily by string) So now I was thinking that instead of designing the program to use a data structure to pass data around, the program would simply pass the model, and then data can be extracted with reflection. This would pretty much avoid any redundancy and the data passed will always be up to date. The problem is that I also need this program to be fast (it has soft realtime constraints), and I'm not sure about the performance impact of reflection. And reflection does seem kinda ugly. But at the same time, people say it's never a good idea to optimize early, so I'm on the fence here. So should I design the program to use reflection, and if so, how liberally? Or should I try to avoid reflection as much as I can during design?