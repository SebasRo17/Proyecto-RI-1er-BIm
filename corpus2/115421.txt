I'm working for a company with very large databases which all refresh overnight, ready for users to interrogate in the morning. These over night loads essentially truncate all the tables, and reload again using pretty complicated business logic. This is all fine and good, but occasionally, rather than going through the proper routes, a quick fix is needed in the business logic, and changes will be made on the "Live" server to the business logic without too much testing. This has, as I'm sure you can imagine, resulted in subtle but significant mistakes being made. I basically want to now independently write logic (in T-SQL probably) which will try to spot any abnormal changes, so at least I'm ahead of the game, and can report them sooner. My question is, fairly obviously, does anyone have any advice on this? Is there any theory or general good practice which I could incorporate to hopefully limit the impact of future "quick and dirty" changes to business logic? Just so you know, we do use source control, and use Live, UAT, and Dev server environments, its just that sometimes, changes need to made immediately, rather than going through the stricter channels.