Dividing a problem to smaller ones until the individual problems can be solved independently and then combining them to answer the original question is known as the **divide and conquer** algorithm design technique. [See: Introduction to Algorithms by CLR] Recently, this approach to solve computational problems especially in the domain of very large data sets has been referred to as **MapReduce** rather than divide and conquer. My question is as follows: Is MapReduce anything more than a proprietary framework that relies on the divide and conquer approach, or are there details to it that make it unique in some respect?