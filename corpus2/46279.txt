I have defined a function to compute the Shannon entropy of a probability distribution:               ent[p_] := Expectation[-Log[PDF[p, x]], x \[Distributed] p]      This works fine for univarite distributions:               nd = NormalDistribution[]     ent[nd]          Out[9]= 1/2 (1 + Log[2 \[Pi]])      I would have expected `ent` to work with multivariate distributions as well, since `x \\[Distributed] p` in `ent` should cause `x` to be bound to vectors of the appropriate length to make `PDF[p, x]` work, but I get               nd2 = ProductDistribution[nd, nd]     ent[nd2] // FullSimplify          Out[10]= Expectation[-Log[        PDF[ProductDistribution[NormalDistribution[0, 1],           NormalDistribution[0, 1]], x]],       x \[Distributed]        ProductDistribution[NormalDistribution[0, 1],         NormalDistribution[0, 1]]]      I can write a specific function for each arity:               ent2[p_] := Expectation[-Log[PDF[p, {x, y}]], {x, y} \[Distributed] p]     ent2[nd2]          Out[11]= 1 + Log[2 \[Pi]]      Is there a way to write ent to be generic wrt to the dimention of the distribution? I would also like to better understand why `ent` does not work for multivariate distributions as is. The definition seems mathematically correct for any dimention.