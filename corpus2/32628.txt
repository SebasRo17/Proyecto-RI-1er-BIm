I need to speed up or parallelize an operation that looks essentially like this:               comparisonSetsA = Round[Table[RandomReal[1., {100, 2}], {k, 1, 100}], 0.05];     comparisonSetsB = Round[Table[RandomReal[1., {100, 2}], {k, 1, 100}], 0.05];          intersectionSizes = Table[Length[Intersection[comparisonSetsA[[a]], comparisonSetsB[[b]]]], {a, 1, Length[comparisonSetsA]}, {b, 1, Length[comparisonSetsB]}] // AbsoluteTiming      Here, we're computing the length of intersections between all pairs of sets in `comparisonSetsA` and `comparisonSetsB` (containing real numbers), which, while less trivial in my actual application, are roughly about the same size as above. Simply writing `ParallelTable` makes things about 3.56 times worse in terms of timings on an 8-core machine. Is there any way to efficiently parallelize or optimize the above process? Note that I cannot make assumptions about the size of any of the intersections, and the sets can be assumed to not contain duplicates. Update - If it helps, I only need to know if the size of the intersection is greater than a smaller threshold value, e.g. $||A \cap B|| \geq 2$ or $3$. I don't need to know anything more than this. Update 2 - I'd like to extend ybeltukov's to handle cases where the sets in A and B are not necessarily of equal size. Is there a simple way to do this that doesn't add much in the way of overhead? I'd asked a question about a possible "padding" method here: http://mathematica.stackexchange.com/questions/32770/equalizing-the-sizes-of- sets-in-an-array-using-non-intersecting-integer-elements Update 3 - Let me be a bit more explicit about Update 2, since I did a poor job earlier communicating. I meant that I would like to extend ybeltukov's very nice result to the cases where internal to sets A and B, the sets are of different sizes. Say, for example, the case where list A has sets of size 5, 6, and 7, and set B has sets of size 8, 9, and 4. I believe one calls these "ragged" lists.