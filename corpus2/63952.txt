In game development there is a lot of C/C++, in business applications C#. I have seen C/C++ devs express concern over how a single line of code translates to assembly. In .NET some go into IL, rarely. In C#, "micro-optimizing" is frowned upon, rare and usually a waste of time. This does not appear to be the case in game development. What specifically creates this inconsistency? Do games constantly push the limits of hardware? If yes, as hardware improves should we expect higher level languages to take-over the gaming industry? _I'm not looking for a debate on the feasibility of C# as a game dev lang. I know it's been done to some degree. Focus on Micro-optimization. Specifically, the difference between Game Dev vs Applications dev._ **UPDATE**   By Game I mean modern, largescale development. E.G. MMORPG's, Xbox, PS3, Wii...