In class I am learning about value iteration and markov decision problems, we are doing through the UC Berkley pac-man project, so I am trying to write the value iterator for it and as I understand it, value iteration is that for each iteration you are visiting every state, and then tracking to a terminal state to get its value. I have a feeling I am not right, because when I try that in python I get a recursive depth exceed. So I return to the pseudo-code, and there is a `Vk[s]` and `Vk-1[s']`, which I had thought to mean value of state, and value of `newState`, but I must be missing something. So what is the significance of the `k` and `k-1`? My Code:                def val(i, state):             if mdp.isTerminal(state) or i == 0:                 return 0.0             actionCost = {}             for action in mdp.getPossibleActions(state):                 actionCost[action] = 0                 for (nextState, probability) in mdp.getTransitionStatesAndProbs(state, action):                     reward = mdp.getReward(state, action, nextState)                     actionCost[action] += probability * reward + discount * val(i - 1, nextState)                     return actionCost[max(actionCost, key=actionCost.get)]              for i in range(iterations):             for state in mdp.getStates():                   self.values[state] = val(i, state)      Pseudo Code:               k ←0      repeat           k ←k+1            for each state s do                Vk[s] = maxa ∑s' P(s'|s,a) (R(s,a,s')+ γVk-1[s'])      until ∀s |Vk[s]-Vk-1[s]| < θ