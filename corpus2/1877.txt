As an example, say there's an interface that contains a table/grid of information that is periodically updated. The table is meant to represent an event that has happened, perhaps the date and time of a stock price change . The acutal frequency of these events could be dozens of events per second. This is obviously too much information for a user to process/understand, so I'm trying to find out how much information a user COULD process in a given amount of time so that we can throttle the data and come up with an alternate display. I know some studies have been done on this, but I can't seem to find an authorative source.