Many programmers tasked to teach a beginning programming class have forgotten a lot of the things that they didn't know or wouldn't know back before they learned how to program themselves. And there are lots of ways to not understand a topic. But some seem to pop up very often among students, no matter what common beginning programming language or textbook is used. An answer to this question lists several misconceptions or lack of conceptions that seem to occur more when teaching programming to people who have zero programming background: What is the best way to teach beginners? (such as confusion about the difference between the environment when a program is written and when it is run, that (basic block) program code executes sequentially, the difference between a variable and its contents, etc.) Another example are the questions from new programmers who simply assume that ordinary variables (in C, Python, etc.) can exactly represent common fractions (1/100ths). Is there an online list or book that covers these concepts, that have to be taught above and beyond the syntax and semantics of the chosen programming language and IDE?