I'm trying to design a system that performs image analysis on video streams from the internet. I have a few rudimentary ideas for how to organize such a system, and I was hoping you guys could critique them and offer suggestions of your own. For clarity, I'm going to present my ideas in the following manner:   1. High-level description of the problem   2. Assumptions and constraints   3. My suggested approach I think this conversation can, for the most part, remain language-agnostic, but FWIW, we're planning on doing this in Go. **I'm looking for a general critique, and advice about how to structure my code.** # 1\. High-Level Description The problem can be generally described as follows: our system is an image processing pipeline that will extract features from video frames with one important caveat: **the remote client will request that a certain subset of proposed analyses be conducted.** In other words, we will offer a variety of analyses, and the client will choose which subset of these analyses he would like us to perform. This is important for two reasons:   1. Image processing is expensive, so we don't want to perform unnecessary computations.   2. Certain high-level features (e.g. facial expression analysis) depend on lower-level features (e.g. face segmentation, person detection, ...) **The goal is therefore to create a pipeline that performs all prerequisite analyses exactly once, but does not perform any superfluous analyses.** # 2\. Assumptions and Constraints A few assumptions and constraints, in no particular order:   1. Frames will enter the pipeline via `stdin`, as base64-encoded byte strings.   2. One process per video stream.   3. Some features can be extracted independently for each frame.   4. Some features require several consecutive frames in order to be computed.   5. We're striving for soft real-time, or at least low-latency. The client is informed of results on-the-fly rather than retrieving them from storage at a later time   6. This service is running on Amazon EC2 (but I think most of the discussion can remain environment-agnostic) # 3\. A Potential(ly stupid) Approach My main concern is in optimizing the pipeline such that all necessary prerequisite computations are performed exactly once and no unnecessary computations are performed. A simple approach would be as follows:   1. Frames are stored in structures with a `feature` hashmap where results of previous computations can be stored.   2. Each possible stage of the pipeline (i.e. "unit of work" that extracts a feature) exists as a structure with methods. Said structure contains metadata information about prerequisite features.   3. At each stage of the pipeline, the frame struct is checked to see if all prerequisites are met. If not, the necessary function is applied and the result is stored in the aforementioned hashmap.   4. The pipeline stage is applied. This solves the problem of not repeating a given computation, but doesn't really define any general pipeline architecture. It's trivial, for instance, to use this method when operating on frames individually, but what about operating on groups of consecutive frames (i.e. a sliding/tiling window over the last _n_ frames)? I eagerly await critiques and suggestions! Thanks in advance!