There is a lot of information about tools and techniques for improving legacy codebases, but I haven't come across any successful real world case studies. Most advice is on the micro level, and while helpful, doesn't convince many people because of a lack of evidence it can help at the macro level. I am looking specifically for incremental improvements that have been proven to be a success in the real world when updating a large legacy codebase to meet today's quality standards, and not a complete rewrite. Before:   * Large: greater than 1MLOC   * Legacy: no automated tests   * Poor quality: high complexity, high coupling, high escaped defects After   * Automated tests   * Easier updates/maintenance   * High quality: lowered complexity, decoupled code, few escaped defects What kind of incremental steps have been proven in the real world to update a large legacy codebase successfully to meet above quality standards, without going through a total rewrite? If possible, include an example company or case study of a large legacy project that has gone through a "successful" quality improvement process in your answer to back it up.