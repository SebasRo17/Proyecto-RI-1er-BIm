It's a known fact that branching is bad for CUDA. The question I have is a little more specific. I have a (static) loop. Static here means that it follows the exact same path every time, and executes the same number of times. Inside the loop are branches, but in a given iteration, the same branch is followed every time. So, if we unwind/unroll this loop, and flatten out obvious branches, it will be plain-old sequential code. Is it worth it to unwind this loop for execution on a CUDA device, or will branch prediction work well enough and execute only one branch per thread? Because otherwise, there are about 34 paths through the code that can be taken, and I'm trying to avoid each thread taking each path. Example loop:               for (int i = 0; i < 33; i++)     {         if (i % 3 == 0)             ...         if (i % 3 == 1)             ...         if (i % 3 == 2)             ...     }