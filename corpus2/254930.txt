I am building a "splitter" for web traffic: a web server that will receive an HTTP request, forward it to two backend servers, choose the best response (for which it needs to parse all of them) and return it to the original requestor. (Just to clarify: it is not a proxy with several backends; each request is forwarded to all backends, and then only one response is returned.) It will need to handle at least 50 thousand requests per second (or 50+ krps) on a single server. Together with a colleague we have built several versions of the splitter. Here are the results:   * Node.js (`http` library): goes up to 6.9 thousand requests per second (6.9 krps).   * Go (`net/http` library): up to 12 krps.   * Erlang (`misultin` and `lhttpc` libraries): up to 7.3 krps.   * Clojure (`http-kit`): 13 krps. None of them are even close to the requirement. According to e.g. the single query of the Web Framework Benchmarks by TechEmpower, which might be roughly equivalent to the splitter, there is room for improvement. The big question is, what should we try next? **Technical details:** The server should handle at least 50 krps on a single server, standard hardware. The requests are POST messages with JSON-encoded bodies of about 1~3 KB, and the responses have similar size. Each request does not need to be parsed, but it can be passed along as is; in the response, at least one specific JSON field needs to be parsed. Each request has a very strict timeout that is between 80 and 450 ms, depending on the URL; if any backend takes longer than that, the server should forget about it and use the remaining backend. If no valid responses are received in time, the server will respond with a 204 No content. **Testing details:** For simplicity, let us say that all requests are all coming from an HAProxy server in front of it, so an Apache `ab` or `wrk` load tester is appropriate. It will run on Amazon EC2, so it should use multiple cores efficiently. For reference let us say it is a c3.2xlarge instance. Both backend servers should reside on a different machine than the splitter (possibly two separate servers, if needed), and ideally the load tester should also be on another machine. It is important to ensure that neither the load tester nor the backends are the bottlenecks here, which is as simple as load testing one of the backends directly and verifying that it gives much better results than the splitter. Results for `wrk` testing the servers returning a constant string:   * Node.js (`http` library): 43 krps.   * Go (`net/http` library): 73 krps.   * Erlang (`misultin` and `lhttpc` libraries): 59 krps.   * Clojure (`http-kit`): I don't have the number, but > 20 krps. Some days ago I asked a question about a splitter-like service in Go, and the answer there allowed me to go up to 6 krps. Further optimizations increased this number to about 12k, although I am not sure that the results will hold in the general case. For instance: I was returning a constant response and not parsing the JSON responses. I am not really sure if our results are reasonable, or if we should be getting much better results with the frameworks we have tried. According to the Web Framework Benchmarks, C++ (with CPoll based C++ server pages) and Java (multiple frameworks) are kings of the game when it comes to rps; but given the effort required to set up, build and test the services in each new framework we want to be sure that we are not getting into any dead ends here. The benchmark above is not really equivalent to our problem; and it is hard to get rps numbers for this kind of proxy-like traffic. I should clarify that it _should_ be possibly to reach the goal, since HAProxy can forward 33 krps with a single core; using the 8 cores in a c3.2xlarge instance, and with anything remotely resembling linearity, it should be within the realms of possibility to reach 50 krps doing two forwards of each request. Writing a multicore web server in C is not in our plans except as a last option, though. This question has been interpreted as too broad on StackOverflow and here by eager editors. So I will reformulate with a clear, straightforward question: Have you built or read about anything similar, with peak performance numbers? (For instance a proxy server for HTTP traffic, even though it would only forward each request to one backend.) Please detail in what language, with what library or framework, and how many requests per second were obtained with a single server.