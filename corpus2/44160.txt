I'm computing a certain power series (up to some number of terms), and I figured I should try to speed up the computation as much as I can. The series is defined as follows: Let $f$ be a Laurent polynomial (EDIT: with integer coefficients) in two variables $x,y$, then $S=\sum_{m\ge 0} const(f^m)t^m$, where "$const(-)$" is the constant term. Naively, we could try               ConstantTerm[function_]:=Coefficient[Coefficient[function,x,0],y,0];     S[function_,order_]:=Sum[ConstantTerm[function^m]t^m,{m,0,order}]      but this seems stupid as the expensive part is computing powers of the polynomial, and this approach repeats that computation for each term instead of taking advantage of the result of the previous term. I tried to do a classical loop construction with `While`, doing something like `tmpfunction=tmpfunction*function` at each step (I won't show the whole thing, because it clearly is barking up the wrong tree), but there was absolutely no appreciable difference in execution time, even for high orders. 1) What is going on here? Does _Mathematica_ do some secret tricks to optimize the naive construction while executing? Is the overhead of manipulating counting variables in the loop big enough to offset the expense of computing the $f^m$? 2) How can it be made more efficient, if at all?