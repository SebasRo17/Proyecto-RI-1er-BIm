I have an $m\times n$ matrix (presumably of full rank) with $m>n$, and I would like to row reduce it, but leave the last column unreduced; that is, I want to get output on the form $\pmatrix{ 1 & 0 & 0 & \ast \\\ 0 & 1 & 0 & \ast \\\ 0 & 0 & 1 & \ast \\\ 0 & 0 & 0 & \ast \\\ 0 & 0 & 0 & \ast}$ instead of $\pmatrix{ 1 & 0 & 0 & 0 \\\ 0 & 1 & 0 & 0 \\\ 0 & 0 & 1 & 0 \\\ 0 & 0 & 0 & 1 \\\ 0 & 0 & 0 & 0 }$ which is what RowReduce gives me. I can't seem to mangle RowReduce into doing it, and I would really like to avoid manually implementing the algorithm. Is there some nice way to do this? Thanks in advance for any help you can give me.