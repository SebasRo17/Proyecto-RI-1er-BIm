I'm trying to understand exactly what `WorkingPrecision`, `AccuracyGoal` and `PrecisionGoal` mean for the result of `NDSolve`. I presume `WorkingPrecision` simply means the number of decimal places used internally by _Mathematica_ at various points throughout the calculation on its scratchpad, and therefore essentially gives upper limit to what the accuracy/precision of final result can be. Now I understand Accuracy/Precision somewhat in the lab sense (Accuracy is how close you are to the true value, Precision is how repeatable the value you get is in some sense; or to use the dartboard analogy-if you're near the bullseye that's accurate-if you hit the the outskirts in the same place 100 times that's precise but not accurate), but not sure I know how these correlate to the _Mathematica_ concepts... If I set `AccuracyGoal->3`, `PrecisionGoal->4` in `NDSolve`, what does that say about the function I get spat out? It looks like the definition on the help pages is that `AccuracyGoal` of 3 would mean 3 significant figures are correct, whereas `PrecisionGoal` of 4 would give 4 digits after the decimal are correct... e.g if the answer spat out is $89.7895$. What does it mean though in this case to say 3 significant figs are correct, but 4 digits after decimal place are also correct? Seems inconsistent (just a rule of thumb?). The help pages also state: > With `AccuracyGoal->a` and `PrecisionGoal->p`, _Mathematica_ attempts to > make the numerical error in a result of size be less than > $10^{-a}+|x|10^{-p}$ Does this mean if I did have `AccuracyGoal->3`, `PrecisionGoal->4` and `NDSolve` spat out $89.7895$ the numerical error would be $10^{-3}+89.7895\cdot 10^{-4}=0.0997895$ ? so my answer is really $89.7895\pm 0.0997895$ ? or is there a different definition of numerical error here? Thanks for any clarifications.