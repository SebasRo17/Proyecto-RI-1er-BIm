I've recently updated one of my PCs (both have the exact same build) to Mathematica 10. After running the exact same notebook (which has two `FindMinimum` calls) on both, the one with Mathematica 10 takes 831 and 19 065 seconds to converge, whereas the old version only takes 27 and 1510 seconds. This is quite a difference! The question is : has anything changed in the implementation of `FindMinimum`, or in the default settings, that would cause this? I checked `WorkingPrecision` and it hasn't changed in MMA10. Any other clues? As a minimal example I checked with the code in this question, and got the same issue.