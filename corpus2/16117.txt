One thing working in Haskell and F# has taught me is that someone in a university smarter than me has probably already found an abstraction for what I'm doing. Likewise in C# and object-oriented programming, there's probably a library for "it", whatever it is that I'm doing. There's such an emphasis on reusing abstractions in programming that I often feel a dilemma between: 1) just coding something short and dirty myself or 2) spending the same time to find someone else's more robust library/solution and just using that. Like recently one of the coders here wrote up a (de)serializer for CSV files, and I couldn't help but think that something like that is probably very easy to find online, if it doesn't already come with the .NET standard APIs. I don't blame him though, several times working in .NET I've patched together a solution based on what I know, only to realize that there was some method call or object or something _,often in the same library,_ that did what I wanted and I just didn't know about it. Is this just a sign of inexperience, or is there always an element of trade- off between writing new and reusing old? What I hate the most is when I run across a solution that I already knew about and forgot. I feel like one person just isn't capable of digesting the sheer quantities of code that comes prepackaged with most languages these days.