**Read first:** For a definition of the two terms ("profiling" and "benchmarking") and the need for distinguishing them, please read this answer to a previous question. I have to admit that until I saw Winston Ewert's answer, I have never thought of the need to distinguish the two techniques. I simply think that "profiling" can be applied at different "scale levels" of software, and that when it is applied on the higher level, the profiling code in the lower levels ought to be turned off in order to lower the aggregate overhead. After I reflected on the answer, it might have explained why I fell prey to micro-optimization in my previous project. In an effort to optimize during that project, I implemented a low-overhead profiler (inserted into the source code) which is good at generating accurate profiling results at the millisecond level. I then spent all days tinkering with it, and optimized a lot of code based on the profiler's result. In the end, I was successful in reducing the _computation_ part of the project from several seconds to less than a fraction of a second. The next thing I learned, to my horror: when the optimized module was used in a larger project, _I/O and data conversion_ completely dominated the module's _computation_ time. The non-computation part is in the range of 1-2 seconds, making my optimization efforts moot. To this date, I still haven't got a chance to do a true "benchmarking", though I am going to give it a try very soon. Given that "Did you do profiling?" has become the cliche on both StackOverflow and Programmers.SE, is there a danger that my kind of ignorance is actually prevalent among fellow developers? Does this ignorance lead to micro- optimizations all over the places?