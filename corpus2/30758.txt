I have a number of large pieces of precomputed data which I am considering putting into individual packages in order to load them (via `DeclarePackage`) and unload them (via Leonid Shifrin's `PackageManipulations` package) as needed. For what it's worth, I have some functions which will be defined on some objects using `UpValues`, and it is the `UpValues` which will be stored in the packages, one for each object. I am wondering if performance or other issues occur, either in the kernel or the front end, when any of the following becomes large (hundreds or thousands): 1) `$Packages`, 2) The number of defined contexts, 3) `$ContextPath`. Is it okay to create new contexts more-or-less at one's convenience, or does one need to be conservative, and if so, how? Some other questions in which this situation might occur are here, here, and here (in Leonid Shifrin's answer.