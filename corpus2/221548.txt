I have a clustering problem which I can't seem to solve, although if I treat it as a labeled classification problem, I can solve it with satisfactory precision. Is there an elegant way to make the leap from being able to solve the classification problem, to being able to solve the clustering one? The details: I have a labeled dataset of movements, from which I extract a features vector for each movement. I can then perform classification of the movements with several tools (SVM, decision trees, etc.) and I get satisfactory results (0.85 precision, which in my case is ok). The problem is, that the real world data I am facing, will of course not be labeled, and is not modeled after the labeled data I have (which means I can't train a classifier on the labeled data, and expect it to perform well on other data). The real world data will for sure not be comprised just of these two classes, it will be comprised of K unknown classes, which I would like to be able to cluster with satisfactory precision. So is it logical to assume that if I can solve the classification problem with high precision, I will be able to solve the clustering problem with high precision? Does it mean that my feature extraction, which works well for the classification, will work well for clustering? Because just throwing clustering algorithms at the problem (k-means, meanshift, dbscan, etc.) doesn't give good results. Usually I just get too many clusters, or just 1 cluster (although I know I have 2 classes), with horrible precision. Btw I am using Python's sklearn.