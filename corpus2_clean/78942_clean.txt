dead set moving mysql database huge set working right time meantime curious technical performance issue regarding speed two method obviously binary jumping huge sorted file nasty hit performance chance finding need chip cache even memory pretty bad assume statistically normal distribution record request across huge file unless whole file memory one working 20gb impossible win32 system using almost certainty large number record request degrade performance killing operation actual hard disk read since never done database index programming really simple b tree indexing wonder good index created modern database like mysql avoiding hard disk hit obviously one big advantage index key lot smaller record represent jam lot index page memory avoids lot disk hit wondering behind index successfully optimize way especially come index page access prediction speed thing even making sure index page access result disk access anyone deep experience kind underlying mysql indexing similar entity done deep performance testing like hear roschler