background local database contains nearly num billion unique row row indirectly associated specific latitude longitude location row date stamp use case problem follows num user set starting ending date range value e g num num num system gather row match given date grouped location num system performs determines location date statistical likelihood falling given range value num system display matching location user problem speed scale question least expensive solution architecture imagine would allow system retrieve result user five second current system environment currently postgresql num upgrade possible switching database option r pl r wd num gb ram g skill num ghz quad core genuineintel num num ghz ubuntu num hardware upgrade acceptable update database structure billion row table resembling id taken location id category value1 value2 value3 id primary key taken date assigned row location id reference latitude longitude category description value1 num value user query taken column typically consecutive date per location id sometimes location num num num num date many duplicated location date range seven category table already split category using child table category contains num million row near future number row per category exceed billion approximately num num location num num city location correlated city latitude longitude assigning location particular city mean finding city boundary trivial task idea idea include find cloud service host database create ssd raid stripe great video create table location city pre calculation thank