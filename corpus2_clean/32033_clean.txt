trying reduce minimum time matrix operation parallelize write code compact form get operation done around sec good matrix around x machine precision number newtotd absolutetiming fullmat nodenumb tempmat try mathematica parallelizing core performance much worse newtotd absolutetiming parallelize fullmat nodenumb tempmat also tried write code explicit form table actually give transposed newtotd matrix result even better newtotd absolutetiming table fullmat nodenumb k tempmat j k j length tempmat k length tempmat expected even worse hoping paralleltable would better wrong aborted evaluation minute newtotd absolutetiming paralleltable fullmat nodenumb k tempmat j k j length product k length product aborted happening guess something related passing matrix back forth kernel avoid course tempmat entry edit operation described first piece code take long lot infinity entry tempmat matrix replace keep track position change corresponding entry resulting matrix still operation take much longer accept get position infinity entry tempmat infpos position tempmat infinity replace table tempmat infpos infpos length infpos absolutetiming newtotd fullmat nodenumb tempmat set corresponding entry newtotd matrix infinties removed absolutetiming table newtotd infpos infpos length infpos perhaps think faster way set infpos entry end