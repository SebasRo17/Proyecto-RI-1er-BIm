trying build system company want check unusual abusive pattern user mainly web scraper currently logic implemented parses http access log take account following parameter calculate potential user scraper bot num check v http post get request ratio ip num calculates ratio unique url total number hit ip based two parameter try block ip showing unusual behaviour two parameter alone sufficient bot detection thus would like know num parameter included improve detection num found paper published acm library follows bayesian approach detect crawler anyone used effective num stack overflow high traffic site kind system deployed logic follow keep unwanted spammer crawler away real time