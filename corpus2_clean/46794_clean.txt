top level function operates data findbestintegers data parallelmap optimize data make parallelized call optimization routine try find best integer associated data point optimization function shown highly simplified form optimize datapoint module bestguess newguess bestcost newcost bestguess randominteger bestcost cost datapoint bestguess newguess randominteger newcost cost datapoint newguess newcost bestcost bestcost newcost bestguess newguess bignumber return bestguess make many call memoized cost function real optimization method using make fair number duplicate call cost function achieves x performance boost memoization cost datapoint n n n cost datapoint n n n rh running long time large data set noticed subkernels memory footprint expanding hundred megabyte due memoized cost function cached locally worry slowdown garbage piling however also know data never contain duplicate point due essentially random floating point number mean write top level function loop optimizes batch data point parallel downside clearing memoized function subkernels free memory moving next batch data point unable get work referencing question clearing distributed definition remote kernel parallelevaluate clear cost unable refresh function definition subkernels error result furthermore certain speed gained suppose depends data structure used memoization within subkernel hash table example basically constant lookup time anyone know performance gained implement sort parallel memoized garbage collection