working moderately sized c base optimization effort becoming uniformly slow base set library combine put work general framework library communicate developed emphasis performance later part added general framework changed much optimization done needed hardware evolved made expensive early decision apparent much later point optimization much expensive since would require rewriting large part base find approaching undesirable local minimum since know principle able much faster successful methodology help decide turn take evolution base towards globally optimally performing solution easily confused easy optimization opportunity edit answer question currently profile really num different scenario used embarrassingly parallel profiling done wall clock time averaged large sample input detailed run instruction cost branch caching issue work well since exclusively extremely homogeneous machine cluster couple thousand identical machine since usually keep machine busy time running faster mean look additional new stuff issue course new variation show might get late comer penalty since removed obvious micro inefficiency use case thus possibly narrowing number optimally running scenario current answer rightly suggest separate algorithm becomes easier adjust