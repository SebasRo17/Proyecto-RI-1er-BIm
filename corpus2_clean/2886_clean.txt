question inspired one whuber answer consider following code randomreal diagonalmatrix exp randomreal absolutetiming randomvariate multinormaldistribution run second let parallelize launchkernels absolutetiming join paralleltable randomvariate multinormaldistribution run second core machine much slower also us lot memory checked using process monitor let suppress returning result subkernels including semicolon absolutetiming join paralleltable randomvariate multinormaldistribution one run second speedup happening calculation return result much slower general rule parallel calculation returning even moderately large data tends lead significant slowdown slowdown due mathlink performance anything one could avoid slowdown warning might eat memory force system swap computer gb everything fine less memory reduce amount data bit solution oleksandr excellent analysis showed performance bottleneck memberq particular unpacks array inside expression tested completely unnecessary possible define efficient though limited version memberq memberq list form matchq form list note memberq test level default unlike freeq test level made easy implement two argument form memberq temporarily change memberq executing parallel operation clearall fix setattributes fix holdall fix expr block memberq memberq expr fix absolutetiming join paralleltable randomvariate multinormaldistribution run second huge improvement illustration fix performance problem code showed completely safe use current form note changing builtins always risky easily cause problem used block localize change reduces risk note block affect calculation parallel kernel fix used parallelization function form fix paralleltable effect function code parallelized reduces risk implement argument form memberq used anywhere parallel tool fix break thing take bit work correctly implement preferably falling back builtin memberq case may always undocumented behaviour memberq aware differs memberq implement short circuiting memberq slower case fixed well potential problem largely fixed bit work believe method work well fixing particular performance problem parallel calculation